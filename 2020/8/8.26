1. 又大致过了一遍在线蒸馏的文章，然后打算看一下知识蒸馏的文章，模型集成的话因为用的是
   简单的结果集成，所以应该不需要太多知识储备。

   然后就是异步的话这个差分隐私如何运用也是问题，因为和同步的环境不同，同步环境下所有
   worker训练的周期相同，异步环境下更像是数据库的查询模式，共享出的模型就类似做出了一
   次查询，现在的想法是各算各的，每个worker只管自己的部分，即统计本地数据的接触次数，并
   以此为依据添加噪声实现隐私保护，共享出去的就不管了。

   然后就是因为是异步环境，无法像同步训练那样，在损失函数上增加相似度损失项来增加模型多样性。
   所以我想可以尝试通过差分隐私引入的噪声来丰富模型多样性，目前想的是控制噪声总量的前提下调整
   加噪位置或方式，这个部分之前有读过文章可以参考，但如何衡量多样性，如何验证是个问题。

   最后就是多样性增强模型集成的性能具体如何，还有待实验验证。