1. 完成了集成部分的代码，然后从结果来看还可以，对加噪声的模型直接应用结果的集成，得到的
   测试集准确度比子模型的平均准确度高了3%

   然后在写知识蒸馏算法时遇到了问题，因为需要先用集成模型进行伪标签的标记再进行知识蒸馏的
   训练，直接导致显存爆掉了，然后试了各种方法都解决不了，最后通过把集成模型的工作转移到CPU
   上，GPU只保留知识蒸馏训练解决了。蒸馏的实验结果比预想要好，集成模型蒸馏出来的子模型几乎
   没有损失精度

   但在把模型集成部分和知识蒸馏部分合在一起时出问题了，本来想的是先进行训练，然后每隔一段时间
   停下训练进行知识蒸馏，完成之后再继续。但用上各种方法，训练都停不下来，变成了一边训练一边蒸馏，
   所以显存又爆了。

   考虑了一下解决办法，要么是改成停下训练，保存模型，知识蒸馏，然后读取模型继续训练；或者是直接
   改成串行的，一个一个训练，一组完成后进行蒸馏，这样的模拟实验。

   最后决定放弃并行，改为串行模拟并行。
   两个原因：1. 是目前的想法是异步，所以其实并行训练不是非常重要的点，在一个机器上进行集成和蒸馏才是。
            2. 目前用的LeNet5属于非常简单的网络结构，后面如果要测试大一点的网络肯定显存更不够。

   明天着手改动代码结构。