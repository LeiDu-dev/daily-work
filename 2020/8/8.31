1. 赶着周末把代码写完了，然后写了一个联邦平均算法作为baseline测试。从实验结果来看效果很好，在手写数字识别任务下：
   1) 当通信间隔为1时(模型聚合时，子模型的训练次数)，fed_avg在epoch为10和30的精度大约为73%和84%，而采用知识蒸馏作为集成手段的对应精度约为89%和91%，分别上涨了16%和7%左右
   2) 当通信间隔为10时，fed_avg在epoch为10时的精度为92.22%,而采用知识蒸馏的精度为95.28%
   从实验结果可以看出，这个idea是有效果的，但目前实验中的差分隐私采用的是现有的第三方库，所以结果和完整的idea还不完全一致，关于差分隐私实现部分还需要再完善。

   还有就是关于模型蒸馏阶段是否需要加入差分隐私我还有点疑问。因为在模型蒸馏阶段的损失是有两个部分组成，一个是真实数据集标签的硬目标，一个是教师模型标记的软目标，而软目标的产生
   是来源于教师模型，即子模型集成后的集成模型，但是集成模型本身就是在差分隐私保护下的。在差分隐私的后处理性质中，当一个函数已经实现隐私保护了，那么之后如果没有再次接触原始数据
   ，那么隐私保护效果不会收到影响。此处仅使用集成模型进行预测，而不是进行训练，所以我认为这部分的软目标应该从隐私保护中排除，即只保护硬目标的部分。但实验中我这部分暂时使用的第
   三方库没法做这样的惊喜修改，所以这里加入的噪声比预定要大。因为这部分只用对某个部分的目标函数实现隐私保护，所以我觉得这里用目标函数扰动最合适。

   而在目前的训练阶段我还在犹豫具体用哪一种，现在还是偏向目标扰动，但这部分的内容还没看过，所以现在的计划是赶紧看这部分的内容以及查找知识蒸馏与差分隐私结合的文章。