1. 在写文章的方法部分，感觉既然允许参与者使用不同的模型进行训练，那再训练出一个统一的全局模型有些怪，所以又加了一个
   收获阶段，即参与者从全局模型进行一个模型蒸馏的步骤。

   然后做了一下在cifar10数据集上的实验，主要是验证了加噪声的实现方式在不进行子采样和进行子采样下的区别：
          RR(resenet)             RR(lenet)         noise(no_sample)        noise(sample)
     10   4837/10000        100   6405/10000        1037/10000              1645/10000	
     20   6034/10000        200   6526/10000         974/10000              1989/10000
     30   6734/10000        300   6597/10000         949/10000              2112/10000
     40   7027/10000        400   6646/10000         987/10000              2293/10000
     50   7332/10000
     60   7298/10000
     70   7428/10000
     80   7474/10000
     90   7600/10000
     100  7674/10000
     200  7999/10000
     
   可以看到，不进行子采样的准确度在10%左右，差不多是随即猜测，带了子采样的实验还没做完，但可以看到和不进行子采样的
   相比准确度有所提升，说明如果要加噪声就得用子采样的隐私放大，但子采样的方法不适合用在输出扰动上，所以输入扰动不适合加噪声。

   然后对比了下不同神经网络的效果，分别是lenet5和resnet18，在集中化学习的环境下，二者在cifar10上的精度分别为65%和80%，
   我主要想看看，如果换成更好的神经网络模型如resnet18，那么伪标签的准确度是不是会有提升，但resnet18的训练速度太慢了，只跑了50个参与者出来。
   但也可以看到30个参与者的聚合结果就超过了lenet400个参与者的伪标签准确度，估计100个resnet18的伪标签准确度在80%左右。

   之后再看下全局模型的效果和加入模型蒸馏后能不能对本地模型有提升。