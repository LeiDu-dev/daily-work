1. 周末加班想了一个新的idea，就是保持原有的整体架构，但是从多个参与者同步协同训练改成异步的形式，但这里叫异步又不太合适，因为我的方案中协同训练时
   各个参与者间，参与者与服务器之间是不需要数据交互的，所以打算叫离线协同学习(offline collaborate deep learning)。

   出发点是在边缘环境下每个参与者都在保持移动状态，难以维持长时间的通信，那么通过一个公共数据集来实现多个参与者的协同训练，可以在参与者只进
   行三次通信下完成协同学习。即每个参与者与边缘节点通信获得公共数据集(1)，然后利用本地模型将其标记后上传结果(2)，接着下载其他人的结果(3)在本
   地进行协同训练。

   自己做实验试了一下，先让7个参与者本地训练100轮，之后用每个参与者的模型标记公共数据集并上传结果，接着对7组结果进行聚合。然后引入一个新的参与者，
   先在本地训练10轮，然后利用其他7个参与者的结果，在本地通过这个公共数据集及聚合预测结果进行训练，这样这个参与者只需要与边缘节点进行三次通信，第
   一次获得公共数据集，第二次上传自己的预测结果，第三次获得其他参与者的结果，不需要像传统的方法一样在协同训练的过程中不断的通信，最终结果来看是可
   以实现协同学习的效果。


   然后是隐私保护的部分：
   1) 一开始想的是直接将预测结果上传，也就是所谓的logits，主要是一个d维的实数向量，然后想的是直接加噪声，但无法确定模型输出的敏感度。

   2) 然后想到用本地差分隐私的方式，就是随机扰动，对一个二进制串进行扰动，比如001010101010，对每一位以一定概率维持不变，一定概率进行反转，
   但这个反转的概率和串长有关，如果一个浮点数想保持精度那二进制串肯定很长，这样反转的概率就很大，再加上logits还有正负，如果符号位反转了那
   直接就没有可用性了。

   3) 接着想到反正上传的logits最后也要通过softmax函数转换成概率向量，模型输出无法控制敏感度，但这个softmax可以，自己算了下敏感度是2，然后加上
   Laplace噪声后扰动效果太强了。而且最开始想的是结果加噪声，然后对加了噪声的结果用softmax，这样可以一定程度减缓噪声的影响，因为知识蒸馏最重要是
   保持结果向量中每个分量的相对大小，如果对结果加入噪声，虽然噪声了影响，不过在softmax处理后可以缓解这种影响。但直接对softmax加噪声直接就影响了
   相对大小，使得整个知识蒸馏没有意义了。

   4) 最后看一篇文章中知识蒸馏不是拟合软标签（即将模型输出的向量或softmax的概率向量作为标签）而是直接将分类结果作为标签，比如：
   对一张图片，模型的输出为: [5.1648,  7.2052,  -1.3512,  -3.1315,  -1.5068,  -4.5608,   -5.6472,   -2.9068,   2.7553,    4.9535]
   如果对其进行softmax处理:  [0.1042,   0.8017,  0.0001,   0.00002,  0.00013,  0.000006,  0.000002,  0.000032,  0.00936,   0.08435]
   可以看到在第二项的概率最大，而其他项的概率非常小，但如果引入“温度”参数，缩小每个概率向量的差距，则：
                            [0.1509,   0.1851,  0.0787,   0.0658,    0.0775,   0.0571,    0.0512,    0.0673,    0.1186,    0.1478]
   可以看到，虽然第二项仍然是最大的，但其他项与他的差距被缩小了，这种输出就是所谓的软标签，知识蒸馏最开始的思想便是让学生模型去拟合这种软标签。

   但如果原样照搬的后果就是对浮点数的处理会非常困难，所以我的方案是，不拟合软标签。对模型的输出logits做argmax处理，以上述第一行输出为例，其argmax结果为1，
   即模型对该输入图片的分类结果为第2类(从0开始)。这样的话用来知识蒸馏的标签不再是[0.1509, 0.1851, 0.0787, 0.0658, 0.0775, 0.0571, 0.0512, 0.0673, 
   0.1186, 0.1478]这样的概率向量，而是 1 (类似于数据集本身的标记，这种一般称为硬标签)。

   接着在隐私保护上，不使用laplace机制或随机响应机制，而是使用指数机制。

   指数机制一般用作给离散数据进行隐私保护，而分类结果刚好是离散的正整数，比如10分类的argmax结果为0,1,2,...,9 刚好契合指数机制的实现。

   同时指数机制是按照一个效应分数进行模糊，比如指数机制处理后，模型输出效应分为100分的的输出几率最大，99分次之，由这种输出的随机性实现隐私保护的效果。
   而在此处，这个效用分刚好可以用模型输出中每一项的大小来分配，因为模型输出的logits中每个值的大小决定了模型对输入的分类判断。
   以上述结果为例，7.2052最大，5.1548、4.9535次之，说明模型认为该输入图片最有可能为第二类，第一类和第十类。这样通过模型输出中每个分类概率的大小排序，
   即实现指数机制中效用分的分配，同时也满足了模型对图片的分类结果是依据输出向量中每个分量的大小的客观事实。

   不过这个隐私保护部分还没做实验，唯一的问题在于如果上传很多个结果的话，可能造成隐私预算的爆炸，但这个可以通过减小上传结果的数量实现，比如10000个数据，
   参与者可以选择上传多少，上传100个数据的结果，服务器就给他发送来自其他参与者的100个数据结果，实现了参与的公平性。

   我觉得这个方案应该比较完美，不过指数机制的部分以前没看过，最近再看，希望赶在这周完成隐私保护部分的实现，如果效果还不错就赶紧写文章，先把大体的框架写了挂
   在arxiv上，哪怕之后再调整细节。
