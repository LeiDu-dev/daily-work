1. 周末一直在做数据，在等效隐私保护等级为epsilon=4的条件下，分别训练了10个，每个包含100个用户的参与者集合。
   然后今天分别用10个参与者集合进行了协同学习测试，然后求了10次结果的平均值。
   在参与者缺失一半类型的数据的情况下，通过100轮训练，总分类精度可以达到95%，低于集中学习98%的效果，但和本方案在
   无隐私保护下的效果接近，我觉得效果算是非常好了。

   然后发现当参与者缺失的训练样本类型过多，好像会导致协同学习失败的问题，即如果10分类问题，参与者只有一类数据，
   那就无法获得知识增益，在缺失一半的情况下可以获得比较好的效果，之后还要测试下缺失6，7，8类数据下的效果。

   还有就是发现同样的代码跑在linux下和跑在windows下效率还真是不一样，之前上课有老师说搞深度学习都应该弄个linux环境运行，一开始没懂为什么，但今天发现同样的代码在linux下明显快得多...所以之后他们要做深度学习下的异常检测还是得搞个双系统。

   接下来准备测试下正常的联邦平均算法的效果如何，不过那不是首要任务，先写文章，目前的实验结果应该已经可以支撑文章发表在arxiv上了。

   最后就是不知道我直接用别人的定义是否可行，他的文章发表在IEEE Transactions on Dependable and Secure Computing
   上，查了下是二区期刊，担心他的内容是不是正确。
   （没事了...发现这个期刊就是TDSC，是安全领域的CCFA刊，那应该不会有问题了...）
