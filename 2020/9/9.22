1. 昨天晚上看了下指数机制的实现，然后发现按照之前的想法实现不了，主要问题还是在邻近数据集和敏感度的定义上，处理不了。
   想到本地差分隐私没有这个限制，转而看LDP，发现有一个人的文章和我的要求几乎一致：按照分数大小输出结果，输出不同结果的概率按照其分数递减，
   即分数最大的（模型认为最有可能的结果）输出概率最大，分数最小的（模型认为最不可能输出的结果）输出概率最小。然后想到这个和地理不可区分性很相似，
   距离近的混淆地址发布概率大，距离远的发布概率小。

   然后发现19年一篇文章做了这个，他把这个LDP的定义叫CLDP，各项都符合我的要求，准备直接用这个。具体来说就是在约束两个变量的相似度时，不只依赖epsilon，
   还倚赖一个距离参数d(v,y)，表示真实值v与发布值间的距离，效果就是距离的近的发布概率大，离得远的发布概率小。

   然后问题是里面用的不是epsilon来衡量，而是alpha来衡量隐私保护效果，从文章中的结果来看，alpha小于epsilon，但正相关。
   如果想让CLDP和LDP实现一样的隐私保护效果得用贝叶斯推断模型去算敌手的最大后验置信(MPC)，然后使CLDP在alpha衡量下的MPC小于LDP在epsilon衡量下的MPC，
   即CLDP实现了和LDP一样或更强的保护强度。
   
   实现起来是先固定epsilon计算出LDP的MPC，然后逐次调整alpha计算CLDP的MPC然后与LDP的MPC比较，直到alpha取最大值。然后试了下在输出域为(0-9)时，
   epsilon取1时alpha取0.367；epsilon取2时alpha取0.947。

   然后测试了一下输出域为(0-99)的结果，epsilon取1时alpha取0.0361；epsilon取2时alpha取0.101，和数据文章中画出的曲线基本一致，因为没有细粒度的刻度和具体
   的数值，所以只能通过图里的曲线看个大概，不过应该是没问题了。

   之后就是实现一下指数机制，这个怎么实现还没想明白细节，因为涉及到概率输出，不知道是不是先计算输出概率，然后用随机数来模拟。
   