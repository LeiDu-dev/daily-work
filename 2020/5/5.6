1. 看了一篇差分隐私和联邦学习结合的文章，他的方法还是用差分隐私随机梯度下降，在每个用户独立计算模型
   参数时用其解决隐私问题，这一点是我之前没想到的，我之前还是有点思维固化在和给参数加噪声，但忘了可以
   直接使用DPSGD这一现成工具。
   
   现在的想法是先代码实现出来，然后对DPSGD，模型直接加噪声，和使用基于数据贡献的敏感度调节机制的上述两种
   方法进行对比再看。
   
   还有就是之前想到如果这样改会不会动摇差分隐私的根本，但我的想法是敏感度调节应该是不会破坏安全保证的，因为
   之前也有其他文献这么做过，但这一部分还需要再参考一下其他的文献来看。