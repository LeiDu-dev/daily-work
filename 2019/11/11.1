1. 早上又看了看论文证明的部分，依然不懂所以决定转变思路，随手翻到之前看了一半的NIPS17的一个tutorial，当时因为机器学习神经网络的知识还没学就看了一半
   这次刚好看完，然后发现这个tutorial主要讲的就是CCS16的那篇文章，看完后对作者思路的理解清晰多了，简而言之就是以前的隐私预算是直接用差分隐私组合定理
   算的，ccs16的这篇文章是单独跟踪隐私预算，所以精度更高，因为目前不打算设计这种机制所以证明的详细部分就先不看。
   
   看教程的时候他提到了几个点我觉得可以探索下：
   1）首先是随机性的问题，随机可以看作是一种隐私保护，同时也可以看作是一种噪声，所以对噪声的引入具有天然的抗性，也就是说有随机性的地方就可以尝试引入差分隐私。
      
   2）问涛涛有没有看过有随机这个概念的机器学习方面的文章，他说了一种通过随机映射来对数据降维，但这个想法又牵扯到第二个问题就是扰动位置的问题，实验表明输入扰动
      效果不如目标函数扰动，而随机映射是对原始数据集进行操作，应该算是输入扰动了，但我觉得这个点可以试试，因为上面说到的随机性抗噪声的原因，这样添加噪声相比直接
      对原始数据加噪带来的效用损失应该小很多，等学了降维后可以做实验尝试一下。但这个idea的问题是要自己证明安全性，而且可能输入扰动的文章比较少，所以可能不好参考。

   3）关于目标扰动，我看最近几年的文章中DPSGD已经使用的很频繁，而且该算法已经被整合到TensorFlow框架中，所以我觉得改进是不可能的了。主要是使用的问题，ccs16的文章
      中只对NN进行了实验，而在CNN或GAN下的表现却可能不一样，针对网络结构的不同或许可以添加些特定步骤来优化，提升使用DPSGD时的性能。
	  
   打算再看看相关文章，然后学一下相关库的使用并试着实现一下2）中的想法，看看效果如何。