1. 复习到了上一次因为看不懂停下的地方，即通过求平均值的例子来更深入的学习拉普拉斯机制与指数机制。
（1）当使用拉普拉斯机制时，全局敏感度|amax-amin|/2太大会导致精度很低，在最坏情况下，仅有极少数点满足条件，
     平均值便会因为一个数据的增减而发生极大的改变。
（2）当使用指数机制时，在最坏情况下，增加一个新的amax会通过效用函数敏感度da改变o=amin的效用，且当满足条件的
     记录量很大时，任何不太接近真实平均值的输出o都不太容易被选中。
     (这里对效用函数的理解有加深，和机器学习中的代价函数类似，是用于描述真实值与当前值之间接近程度的函数)
（3）结合拉普拉斯机制与序列组合机制，即将求平均值分为两个部分：求和与计数，与此同时隐私预算ε也分为sum和count两部分使用。
     详细来说就是针对求和sum和计数count分别加噪，并将加噪结果相除得到结果，其中sum的敏感度为amax-amin，而count的敏感度为1。
     为使结果满足ε-DP，需要sum和count分别满足ε/2-DP。
（4）为了精确计数即不对count添加噪音，去除（3）中对count加噪的部分，计算得到结果为exp(z-a')，其中z无界可任意大故不满足ε-DP。
     为使其满足要求，故考虑将输出结果限制在(amin,amax)，从而引出PING系统，其做法是当结果超出(amin,amax)便重新采样噪音值，
     直到结果落入范围内。但这样会放大每一个输出o的概率，放大的系数为1除以加噪后概率密度。然而当邻近数据集有不同的平均值时，
     概率密度也会不同，最终会使用不同的放大系数，这一差异也同样会被(amin,amax)与ε所影响，从而使得该算法不满足ε-DP。
     (这一部分关于这个放大系数的内容还是没看懂，虽然后面给出了当D与D'有不同平均值的例子，但其中哪个是放大系数没有写，
     放大系数不同会如何影响算法对ε-DP的满足情况以及为什么也没有讲。上面计算结果为exp(z-a')我也没有复现出来，文中是给出式子后直接跳步到结果...)
（5）对上述（4）进一步修改，将重新采样噪音值的方法改为将输出限制到期望区域的方法，并规定在无满足条件的数据时返回答案的方案。
     虽然使得概率分布在amin与amax处离散，在(amin,amax)之间连续，但该方法满足ε-DP。相比于（3）中的方法，因为没有对count部分添加噪音，
     所以sum部分使用了全部的隐私预算ε，而不是（3）中的一半。
（6）对（5）中使用了全部的隐私预算进一步优化，通过一个简单的正则化技巧将sum部分的隐私预算减半。 (但这个方法的原理都没看懂...文中也没有解释)
（7）从表现上来说，从好到坏的排序为(5)(6)(2)(3)。当隐私预算ε很大时，(5)(6)比较相近且其L1误差大约是另外两个算法的一半；当ε很小时，(5)的优点远大于(6)。
    
2. 之后又进行了一部分差分隐私新的学习，主要是差分隐私应用时的四种情况：
（1）本地隐私：在该情况下不存在可信第三方，所有参与者都扰动并上传数据。可以看作是随机响应在回答非二进制值情况下的泛化。
（2）交互式查询应答：存在可信数据管理员可接触原始数据且处于用户与数据库之间。数据库管理员仅在查询被提交时进行应答，而不知道将来查询的内容。
     由于隐私预算有限，故存在缺陷，即当隐私预算用尽，为了不违反差分隐私将无法回答其余查询。且同样因为隐私预算有限故无法适用于多个用户的情况。
（3）单一工作负载：存在可信数据管理员可接触原始数据且处于用户与数据库之间。数据库管理员以私有方式进行数据分析任务，并发布结果。
     (该情况下将差分隐私与机器学习相结合，大多数方式试图通过每一步都保护隐私从而适应现有机器学习算法，另一种方法是扰动机器学习中的优化目标函数)
（4）非交互式发布：存在可信数据管理员可接触原始数据且处于用户与数据库之间。数据库管理员发布输入数据集的概要，从中可回答大量查询问题并生成合成数据。