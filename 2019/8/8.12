1. 在用私人数据原则检验差分隐私有效性时还需要注意以下问题：
（1）在某些情况下，某人合法控制其他人的个人数据，这时应用差分隐私会存在问题。因为对控制者而言，
     隐私安全不仅指自身数据的安全，还包括其控制的其他人的数据的安全。
（2）如果“群体隐私”的概念得到承认，那么将差分隐私用于个人数据就会出现根本性的缺陷，因为其无法
     保护群体隐私。
（3）在公众普遍受益于数据共享的情况下，可以支持使用差分隐私；但当受益者是少部分人时，就会存在
     道德问题，如：通过对出售的数据进行差分隐私处理来获利是不可接受的。
   
   除开上述问题，在应用差分隐私时还需注意：
（1）对隐私预算ε的取值本质上是一个社会学问题，通常取0.01、0.1，ln2或ln3，在绝大部分情况下，
     ε=0.1可以满足要求并提供较强的隐私保护。
（2）在机器学习中应用差分隐私应该在学习模型时使用差分隐私，而不是在使用模型进行预测时使用，
     因为会破坏实用性。但后者又会导致其他的隐私问题，即如果用户未同意，那么使用用户信息进
     行预测是对隐私的侵犯。
（3）对于隐私的保护会造成某种形式的歧视现象(统计歧视)，且保护的情况越好，歧视的现象越严重。
     如当A地区犯罪案件较多时，对A地区人员犯罪背景的保护会使A地区未犯罪人员受到歧视。差分隐私
     无助于解决这一问题。
	 
2. 学习了机器学习在进行系统设计时的注意事项：
（1）确定工作的优先级，即根据之前学习的内容，有目的的选择不同的手段来减小误差。
（2）误差分析：人工检查存在误差的例子，对误判较多的例子进行分析并处理。
（3）Precision/Recall：通过计算查准率和召回率，以及计算F1score来分析并优化算法。
