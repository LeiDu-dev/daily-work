1. 和之前相反，当不存在一个合适的分区时，即要么存在预定义分区，但是每个bin的平均数据点数量很低
  （添加的噪声可能会超过大多数bin的真实数量），要么bin的数量太大，以至于无法枚举所有的bin（实数）。
   而在另一种情况下，直方图的bin的粒度比输入数据更粗，一个查询可能只包含一些bin的一部分。因此，在回
   答查询时有两个误差源，噪声误差和非均匀误差。
    1) 噪声误差是由于bin内计数是有噪声的，当对含噪计数加和以回答查询时，便会产生误差。因此，划分域
       的粒度越细，查询中包含的bin就越多，噪声误差也越大（噪声误差的大小等于回答查询所用bin的噪声的和）。
    2) 非均匀误差是由与查询相交但未包含在查询中的bin引起的，通常会在假设bin内数据点均匀分布的情况下估计
       有多少点在相交的bin内，但是当分布不均匀时便会存在误差。因此，划分域的粒度越细，每个单元格中包含的
       数据点就越少，非均匀误差也越小（均匀性误差的大小通常取决于相交单元格中的数据点的数量并受其限制）。
   
   由此可见噪声误差与非均匀误差在对划分粒度大小的需求上是有冲突的，故在该情况下的挑战在于如何在满足要求的
   前提下调节噪声误差与非均匀误差的冲突（最小化两种误差的和），于是提出以下方法：
   
（1）均匀网格法(UG)：该方法将数据域等分为M个网格并获得每个单元的含噪计数，故其精确度高度依赖网格大小M。
                     其缺点在于平等的对待数据集中的所有区域，但当某个区域只有很少的数据点时，会导致过划分，
                     在小幅度减小非均匀性误差的同时增加噪声误差；而当某个区域数据点很密集时，会导致欠划分，
                     非均匀性误差将相当大。
					 
（2）自适应网格方法(AG)：在理想状态下，当一个区域比较密集时，应该用更细粒度的分区，因为该区域的非均匀性误差
                         远远大于噪声误差；而当一个区域比较稀疏时，相反应该用更粗粒度的分区。基于此提出自适应
                         网格法，即先粗糙的划分为m1*m1个网格，在此基础上基于各个网格的含噪计数来进一步划分。
						 
   关于如何选择划分有如下方法：
    1) 噪声优先方法：首先计算一个平坦的噪声直方图，然后通过动态规划对噪声数据进行bin合并以减少误差。
    2) 结构优先方法：使用一半的隐私预算来得到适合数据和噪声的结构，并使用隐私预算的另一半来发布基于
                     所选结构的拉普拉斯机制的直方图。
    3) DAWA(数据感知和工作量感知)算法：首先计算每个可能间隔的成本，并在此成本中添加一定的噪声，然后
                                       使用动态规划的方法选择噪声成本最低的间隔组合。
    4) 离散傅里叶变换
	
   除上述方法外还可以用递归的方法来进行划分，如KD树, 四叉树，KD混种，P-H划分。但递归分区的方法需要很多步才能
   达成最终的划分，因此产生两个问题：
    1) 隐私预算必须分成很多部分，这样每个个体的选择可能没有足够的隐私预算来做出准确的选择。
    2) 这是一种贪婪的做法。在每次迭代中，算法所做的决策最多是局部最优的。
   
   
   结论：在数据无关的方法中，具有约束推理和较大分支因子的层次直方图表现最好；
         而在数据相关的方法中，AG和DAWA是表现最好的两种算法。
		 
  （第四章看的没前几章细，因为发布直方图是中心化的差分隐私，第五章才是机器学习中的差分隐私，但第四章的内容
    感觉是差分隐私一个基础的应用，在查一下资料的时候经常会看到这个方向，所以花时间看了一下）
