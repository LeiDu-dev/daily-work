1. 差分隐私学习了约束推理。在对给定数据集的多个查询中，其回答应该满足某个约束，但因为独立随
   机噪声的添加，这些约束经常被打破，利用这些约束可以提升随机回答的精确度。
   以层次直方图为例，不同层次的查询结果应该满足某个一致的约束，即每个内部节点的计数应该等于其
   所有子节点计数的和。但当添加噪声后，上述约束很可能不再满足，因为同一个查询可能因为随机噪声
   得到多个不同的回答，实际上这多个不同的回答是关于同一个真实值的多个被噪声扰乱的估计值，直观
   上来说，对其计算平均值会得到更准确的结果。
   
   约束推理有两个阶段：
  （1）加权平均：从叶节点开始到根节点，通过节点原始噪声计数的加权平均数和子节点的总计数的总和
                 来更新每个节点。
  （2）平均一致：从根节点开始到叶节点，更新每个节点，使每个节点的子节点的和与该节点的计数相同，
                 提高子节点在处理过程中的准确性。该步骤通过将子节点与父节点的值的差平均分配给
                 所有的子节点，来确保每个子节点的值的和等于父节点的值。
  
   经过上述两个阶段后，每个节点的值是层次结构中所有节点原始噪声计数的加权和，且可以将方差(MASE)
   大约减少三倍。


2. 学习了聚类的方法，通过不断调整簇的中心点逐渐将样本进化划分。在运行中存在以下两点：
（1）初始化中心点时可能得到局部最优解而无法得到全局最优解，该问题可以通过随机初始化来解决，
     即将初始化中心点随机执行多次并选取其中代价函数最小的。
（2）对于选择划分簇的数量的问题，可以尝试“肘部原则”，但也可能不适用；该问题主要是还是要看
     聚类的目的，根据下一步的目的来选择划分的数量。