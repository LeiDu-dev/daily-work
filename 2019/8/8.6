1. 差分隐私进入新的章节What Dose DP Mean?就今天学习的部分来说主要是差分隐私形成的过程。
（1）首先是介绍了k匿名的概念，其可以抵御再认证攻击，但无法阻止属性泄露，由此又诞生了其他隐私保护方法。
     但以上方法都是语义上的，它们定义了最终数据集的一个属性，却没有考虑获得输出的算法，而差分隐私刚好相反。
（2）任何隐私保护算法都需要考虑实用性，若不考虑实用性便可以发布完全虚假的信息来保护隐私，但若知道隐私保护
     算法的实际用途就会使得一个人可以从给定输出中推断出额外的输入信息。
（3）社会与法律中对隐私的定义是多方面的，在此选择两条与数据隐私相关的，即"privacy as secrecy"与"privacy as control"。
     前者是指“个人有权隐瞒不光彩的事情”，而后者是指“个体有权选择何时，何种方法，何种程度的信息与他人沟通”。 这两种
     概念可以联系到数学上两种定义隐私的方法，分别是"prior-to-posterior"与"posterior-to-posterior"。
（4）"privacy as secrecy"是不可行的，因为该方法以限制敌手关于某个人前后看法改变为前提定义隐私，而现实中这是做不到的。
     例如关于吸烟者易得肺癌的研究报告的发表，会使得保险公司重新审视吸烟者的保险金额，而吸烟者本人不希望这项报告发表，
     因为这侵犯到了他的隐私权，因此如果要阻止保险公司改变看法只能破坏该报告的实用性。
     文中引用文献将隐私定义为“对统计数据库的访问不应使人能够了解任何没有访问权就无法了解的个人的信息”，在上述例子中，
     保险公司并无权访问研究数据库获得病人的数据，但却由结果可以推断出吸烟者易患癌症这一个人信息，侵犯了隐私权。
（5）由（4）中的结论，催生出了一个新的理论，即在不限制敌手先前对数据集分布的看法的情况下实现隐私，就要对任意两个数据集
     发布本质上相同的信息。由此又得出了“理想世界-现实世界”思想，即要求敌手在使用隐私保护方案时得到的信息与在理想情况下
     无额外信息泄露时得到的信息不可分。(这已经很接近差分隐私的思想了)
	 
2. 继续学习机器学习，主要学习了过拟合问题的产生原因，即特征值过多使得假设函数对训练数据集拟合的非常好但却不能泛化到
   新的例子中。针对该问题主要学习了两种方法，减少特征值的数量与使用正则化的方法来缩小特征值的影响，因为在实际使用中
   无法确定应该消去哪一个特征值，故正则化的方法更实用。简单来说，正则化就是在代价函数后加一项使得特征值缩小，从而降
   低特征值的影响，但也不能使特征值过小，否则会从过拟合变为欠拟合。在此基础上又学习了线性回归下梯度下降与正规方程的
   正则化方法，及对数回归下梯度下降的正则化。
   (因为在机器学习中应用差分隐私需要对机器学习算法有深刻理解，这样才能理解在何处需要保护隐私及如何进行隐私保护，所以
   决定放慢差分隐私的进度来等机器学习的进度，等对机器学习的理解比较深入后再进行差分隐私结合机器学习内容的学习，这样
   应该更好理解此内容，顺便也可以再多看看差分隐私的基础部分，感觉目前对拉普拉斯机制理解已经有很大提升，但对指数机制的
   理解依然没有形成体系)