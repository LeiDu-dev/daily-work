1. 差分隐私最近每天学的知识比较零碎，所以用按次序来记录。
（1）对于层次直方图中的隐私预算分配问题，当感兴趣的查询是从所有范围查询中均匀选择时，
    1) 如果将隐私预算分配的选择与分支因子相适应，并应用约束推理，那么许多分支因子的性能都非常相似。
    2) 如果选择最优的分支因子并将其与约束推理相结合，则使用默认的等隐私预算分配与使用最优预算分配一样有效。
	
（2）小波变换，简单来说就是对每个节点v不再发布该节点下叶节点的噪声和，而且发布Harr系数，通过该方法可以重建
     任何节点的噪声计数。就效用而言，应用小波变换类似于对二叉树进行约束优化的效果，且是没有将最优分支因子与
     约束推理结合起来的情况，又因为该方法只能应用于二叉树而不能用于分支因子不是2的情况，故此技术没有实用价值。

（3）矩阵机制，该方法对计数查询的工作负载进行了优化。通过将一组查询表示为矩阵，并通过该矩阵找到另一个矩阵称为
     查询策略，对查询策略添加标准拉普拉斯噪声后，策略查询的答案用于派生原始工作负载的答案。因此，该方法目标是
     确定最佳的查询策略，以便以最小的误差回答给定的工作负载查询。

（4）使用层次结构和约束推理的思想可以应用于更高的维度，但随着维数的增加，层次结构的优势会快速消失。这是因为当
     使用层次结构来回答一个大的查询时，对于使用内部节点回答的部分，会获得显著的收益，但仍然需要使用叶节点来获
     得边界区域的答案，且维数越高，等宽的“边界”所占的百分比就越大。

2. 学习了降维，通过一些方法把高维数据集映射到低维数据集，其目的一个是数据压缩，另一个是数据可视化。
   主要学习的方法是主成分分析法(PCA)，即找出一个向量将数据投影到该方向上并满足在该方向上投影误差最小。
  （但该方法背后的原理没有讲）在运用该方法时需要进行主成分k的选择，选择时依次尝试k值，并选择满足使均
   方投影误差与数据总方差的比值小于某个值的最小值。同时PCA可以用于减少数据存储空间与加速机器学习，
   但不应该用于防止过拟合。