1. 学习了差分隐私中的重要内容，即拉普拉斯机制。
   简单来说就是在原函数后加上符合拉普拉斯分布的噪音以达到保护隐私的目的，为了方便理解，在学习时分为了原函数输出标量和向量两种情况，
   但前者其实是后者的特例。因为这一部分内容比较重要，所以中间给出的证明都自己推导了一遍，发现对概率论中的知识有一定要求，需要抽时间复习一下。
   
   对于输出标量的情况很好理解，即在函数输出后附加一个噪音即可；而在输出向量的情况下，因为函数的输出是由多个分量组成的向量，
   所以在输出后加的噪音也应该是和其维数相同的向量。在输出向量的情况下联想到上一节学到的平行组合，感觉拥有多个分量的向量和
   被划分为多个部分的数据集有某种联系，所以二者在后续的学习中应该会有结合的应用。
   
   文中在每种情况后都附加了一到两个具体应用的例子，其应用的情景和问题很容易明白，但因为到现在为止没有给出任何具体应用的详细过程，
   所以对其在例子中往往一带而过的解决问题的方法不是很好搞明白为什么和怎么做。
   
2. 机器学习学到了线性代数基础知识部分，因为是考研数学的内容，所以跟着老师回顾了一遍线性代数的知识。