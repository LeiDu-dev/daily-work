1. 上午高级计算机网络，下午论文写作指导，晚上大组会。抽空复习了下之前那篇文章摘要，这篇文章中神经网络的激活函数
   用的不是西瓜书里的sigmoid函数而是ReLUs,所以又查了下这个，接着深入了解了下常用激励函数的横向对比，然后在一篇
   博客中提到了ReLUs有一种变体noisy ReLUs，他是普通的ReLUs添加了高斯噪声得到的，常用在机器视觉任务里的restricted Boltzmann machines中，
   然后想到给神经网络的激活函数加噪声这个点不知道是不是可以结合差分隐私。	
   感觉现在看的很杂，因为DP和ML的结合设及到DP和ML两个大方向，然后就需要补很多课，导致论文的阅读进度一直没有动。