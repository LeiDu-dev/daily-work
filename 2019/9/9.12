1. 今天结合知乎上的总结，仔细读了Differentially Private Machine Learning: Theory, Algorithms, and Applications，
   但是没读完，感觉当务之急是赶紧把机器学习的水平提升起来，还有就是概率论的回顾，差分隐私引入的噪声不论是拉普拉
   斯机制，指数机制还是高斯机制都是服从各种特定分布的。
   
   根据教程的内容，在机器学习中应用差分隐私主要有4种途径，分别是输入，目标函数，优化过程，输出。输入和输出的思想
   很类似于拉普拉斯机制，即直接加入噪声，但对输入添加噪声会严重破坏算法可用性。目标扰动和优化扰动即在目标函数和
   优化过程中添加噪声，形成差分隐私保护。
   
   在知乎的总结里，作者提出的一个想法很有意义，实验数据表明相比于非隐私保护的机器学习算法，引入差分隐私的机器学习
   算法的准确度伴随正则化参数的增大，迎来峰值，也就是说正则化项有利于形成隐私保护。从直觉上来说，抑制过拟合的目的
   是避免模型偏离数据的泛化特征，学到数据集的局部特征，而差分隐私是希望减少个体数据对最终模型的影响。从这个角度来看，
   二者是有交集的。不过这些可能有人开始研究了，现在的任务还是先打基础和看论文，感觉在机器学习种引入差分隐私的研究
   主要都是理论性的，研究都集中在算法的改进上，不过也可能是目前看的都是水平比较高的论文。